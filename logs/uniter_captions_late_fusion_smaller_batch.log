2021-04-15 11:54:18.633352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Some weights of BertU were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at /home/ML_courses/DL2020/efratblaier/test-mlm-large-batch-roberta-100-epochs-captions-no-rand were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /home/ML_courses/DL2020/efratblaier/test-mlm-large-batch-roberta-100-epochs-captions-no-rand and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Load 8596 data from split(s) train.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 8596 images in file data/HM_img.tsv in 517 seconds.
Use 8596 data in torch dataset

Load 500 data from split(s) dev_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 500 images in file data/HM_img.tsv in 410 seconds.
Use 500 data in torch dataset

UNEXPECTED:  []
MISSING:  ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']
ERRORS:  []
REINITING:  Linear(in_features=1792, out_features=3584, bias=True)
REINITING:  GeLU()
REINITING:  LayerNorm((3584,), eps=1e-12, elementwise_affine=True)
REINITING:  Linear(in_features=3584, out_features=2, bias=True)
REINITING:  Sequential(
  (0): Linear(in_features=1792, out_features=3584, bias=True)
  (1): GeLU()
  (2): LayerNorm((3584,), eps=1e-12, elementwise_affine=True)
  (3): Linear(in_features=3584, out_features=2, bias=True)
)
Load pre-trained model from ./data/uniter-large.pt

Weights in loaded but not in model:
cls.predictions.bias
cls.predictions.decoder.weight
cls.predictions.transform.LayerNorm.bias
cls.predictions.transform.LayerNorm.weight
cls.predictions.transform.dense.bias
cls.predictions.transform.dense.weight
feat_regress.bias
feat_regress.net.0.bias
feat_regress.net.0.weight
feat_regress.net.2.bias
feat_regress.net.2.weight
feat_regress.weight
img_embeddings.mask_embedding.weight
itm_output.bias
itm_output.weight
region_classifier.net.0.bias
region_classifier.net.0.weight
region_classifier.net.2.bias
region_classifier.net.2.weight
region_classifier.net.3.bias
region_classifier.net.3.weight

Weights in model but not in loaded:
embeddings.position_ids

Total Iters: 7165
Splits in Train data: ['train']
Splits in Valid data: ['dev_seen']
Batches: 1433
/home/ML_courses/DL2020/efratblaier/vilio_env/lib/python3.7/site-packages/torchcontrib/optim/swa.py:130: UserWarning: Casting swa_start, swa_freq to int
  warnings.warn("Casting swa_start, swa_freq to int")
tensor([-0.2944, -1.3663], device='cuda:0')
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)

Epoch(U) 0(250): Train AC 60.67 RA 51.2892 LOSS 1037.5801

Epoch(U) 0(250): DEV AC 50.60 RA 49.4503 
Epoch(U) 0(250): BEST AC 50.60 RA 49.4503 
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)

Epoch(U) 0(500): Train AC 63.40 RA 57.7505 LOSS 973.7457

Epoch(U) 0(500): DEV AC 57.60 RA 66.9104 
Epoch(U) 0(500): BEST AC 57.60 RA 66.9104 
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)

Epoch(U) 0(750): Train AC 65.11 RA 62.2341 LOSS 953.7046

Epoch(U) 0(750): DEV AC 53.20 RA 66.0223 
Epoch(U) 0(750): BEST AC 57.60 RA 66.9104 
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)

Epoch(U) 0(1000): Train AC 66.85 RA 65.8305 LOSS 876.8699

Epoch(U) 0(1000): DEV AC 55.40 RA 72.4120 
Epoch(U) 0(1000): BEST AC 55.40 RA 72.4120 
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)

Epoch(U) 0(1250): Train AC 68.16 RA 68.5837 LOSS 845.6638

Epoch(U) 0(1250): DEV AC 62.20 RA 74.2571 
Epoch(U) 0(1250): BEST AC 62.20 RA 74.2571 
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)
/home/ML_courses/DL2020/efratblaier/vilio/entryU.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  caption_input_ids = torch.tensor(input_ids)
tensor([-3.3211, -0.0368], device='cuda:0')
