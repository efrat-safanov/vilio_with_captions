2021-05-01 02:06:22.196769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Some weights of BertU were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Load 8596 data from split(s) train.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 8596 images in file data/HM_img.tsv in 51 seconds.
Use 8596 data in torch dataset

Load 500 data from split(s) dev_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 500 images in file data/HM_img.tsv in 39 seconds.
Use 500 data in torch dataset

UNEXPECTED:  []
MISSING:  ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']
ERRORS:  []
REINITING:  Linear(in_features=1024, out_features=2048, bias=True)
REINITING:  GeLU()
REINITING:  LayerNorm((2048,), eps=1e-12, elementwise_affine=True)
REINITING:  Linear(in_features=2048, out_features=2, bias=True)
REINITING:  Sequential(
  (0): Linear(in_features=1024, out_features=2048, bias=True)
  (1): GeLU()
  (2): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)
  (3): Linear(in_features=2048, out_features=2, bias=True)
)
Load pre-trained model from ./data/Epoch10_train_BU_hateful.pth
SAVING bert.embeddings.position_ids as embeddings.position_ids.
SAVING bert.embeddings.word_embeddings.weight as embeddings.word_embeddings.weight.
SAVING bert.embeddings.position_embeddings.weight as embeddings.position_embeddings.weight.
SAVING bert.embeddings.token_type_embeddings.weight as embeddings.token_type_embeddings.weight.
SAVING bert.embeddings.LayerNorm.weight as embeddings.LayerNorm.weight.
SAVING bert.embeddings.LayerNorm.bias as embeddings.LayerNorm.bias.
SAVING bert.img_embeddings.img_linear.weight as img_embeddings.img_linear.weight.
SAVING bert.img_embeddings.img_linear.bias as img_embeddings.img_linear.bias.
SAVING bert.img_embeddings.img_layer_norm.weight as img_embeddings.img_layer_norm.weight.
SAVING bert.img_embeddings.img_layer_norm.bias as img_embeddings.img_layer_norm.bias.
SAVING bert.img_embeddings.pos_layer_norm.weight as img_embeddings.pos_layer_norm.weight.
SAVING bert.img_embeddings.pos_layer_norm.bias as img_embeddings.pos_layer_norm.bias.
SAVING bert.img_embeddings.pos_linear.weight as img_embeddings.pos_linear.weight.
SAVING bert.img_embeddings.pos_linear.bias as img_embeddings.pos_linear.bias.
SAVING bert.img_embeddings.LayerNorm.weight as img_embeddings.LayerNorm.weight.
SAVING bert.img_embeddings.LayerNorm.bias as img_embeddings.LayerNorm.bias.
SAVING bert.encoder.layer.0.attention.self.query.weight as encoder.layer.0.attention.self.query.weight.
SAVING bert.encoder.layer.0.attention.self.query.bias as encoder.layer.0.attention.self.query.bias.
SAVING bert.encoder.layer.0.attention.self.key.weight as encoder.layer.0.attention.self.key.weight.
SAVING bert.encoder.layer.0.attention.self.key.bias as encoder.layer.0.attention.self.key.bias.
SAVING bert.encoder.layer.0.attention.self.value.weight as encoder.layer.0.attention.self.value.weight.
SAVING bert.encoder.layer.0.attention.self.value.bias as encoder.layer.0.attention.self.value.bias.
SAVING bert.encoder.layer.0.attention.output.dense.weight as encoder.layer.0.attention.output.dense.weight.
SAVING bert.encoder.layer.0.attention.output.dense.bias as encoder.layer.0.attention.output.dense.bias.
SAVING bert.encoder.layer.0.attention.output.LayerNorm.weight as encoder.layer.0.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.0.attention.output.LayerNorm.bias as encoder.layer.0.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.0.intermediate.dense.weight as encoder.layer.0.intermediate.dense.weight.
SAVING bert.encoder.layer.0.intermediate.dense.bias as encoder.layer.0.intermediate.dense.bias.
SAVING bert.encoder.layer.0.output.dense.weight as encoder.layer.0.output.dense.weight.
SAVING bert.encoder.layer.0.output.dense.bias as encoder.layer.0.output.dense.bias.
SAVING bert.encoder.layer.0.output.LayerNorm.weight as encoder.layer.0.output.LayerNorm.weight.
SAVING bert.encoder.layer.0.output.LayerNorm.bias as encoder.layer.0.output.LayerNorm.bias.
SAVING bert.encoder.layer.1.attention.self.query.weight as encoder.layer.1.attention.self.query.weight.
SAVING bert.encoder.layer.1.attention.self.query.bias as encoder.layer.1.attention.self.query.bias.
SAVING bert.encoder.layer.1.attention.self.key.weight as encoder.layer.1.attention.self.key.weight.
SAVING bert.encoder.layer.1.attention.self.key.bias as encoder.layer.1.attention.self.key.bias.
SAVING bert.encoder.layer.1.attention.self.value.weight as encoder.layer.1.attention.self.value.weight.
SAVING bert.encoder.layer.1.attention.self.value.bias as encoder.layer.1.attention.self.value.bias.
SAVING bert.encoder.layer.1.attention.output.dense.weight as encoder.layer.1.attention.output.dense.weight.
SAVING bert.encoder.layer.1.attention.output.dense.bias as encoder.layer.1.attention.output.dense.bias.
SAVING bert.encoder.layer.1.attention.output.LayerNorm.weight as encoder.layer.1.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.1.attention.output.LayerNorm.bias as encoder.layer.1.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.1.intermediate.dense.weight as encoder.layer.1.intermediate.dense.weight.
SAVING bert.encoder.layer.1.intermediate.dense.bias as encoder.layer.1.intermediate.dense.bias.
SAVING bert.encoder.layer.1.output.dense.weight as encoder.layer.1.output.dense.weight.
SAVING bert.encoder.layer.1.output.dense.bias as encoder.layer.1.output.dense.bias.
SAVING bert.encoder.layer.1.output.LayerNorm.weight as encoder.layer.1.output.LayerNorm.weight.
SAVING bert.encoder.layer.1.output.LayerNorm.bias as encoder.layer.1.output.LayerNorm.bias.
SAVING bert.encoder.layer.2.attention.self.query.weight as encoder.layer.2.attention.self.query.weight.
SAVING bert.encoder.layer.2.attention.self.query.bias as encoder.layer.2.attention.self.query.bias.
SAVING bert.encoder.layer.2.attention.self.key.weight as encoder.layer.2.attention.self.key.weight.
SAVING bert.encoder.layer.2.attention.self.key.bias as encoder.layer.2.attention.self.key.bias.
SAVING bert.encoder.layer.2.attention.self.value.weight as encoder.layer.2.attention.self.value.weight.
SAVING bert.encoder.layer.2.attention.self.value.bias as encoder.layer.2.attention.self.value.bias.
SAVING bert.encoder.layer.2.attention.output.dense.weight as encoder.layer.2.attention.output.dense.weight.
SAVING bert.encoder.layer.2.attention.output.dense.bias as encoder.layer.2.attention.output.dense.bias.
SAVING bert.encoder.layer.2.attention.output.LayerNorm.weight as encoder.layer.2.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.2.attention.output.LayerNorm.bias as encoder.layer.2.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.2.intermediate.dense.weight as encoder.layer.2.intermediate.dense.weight.
SAVING bert.encoder.layer.2.intermediate.dense.bias as encoder.layer.2.intermediate.dense.bias.
SAVING bert.encoder.layer.2.output.dense.weight as encoder.layer.2.output.dense.weight.
SAVING bert.encoder.layer.2.output.dense.bias as encoder.layer.2.output.dense.bias.
SAVING bert.encoder.layer.2.output.LayerNorm.weight as encoder.layer.2.output.LayerNorm.weight.
SAVING bert.encoder.layer.2.output.LayerNorm.bias as encoder.layer.2.output.LayerNorm.bias.
SAVING bert.encoder.layer.3.attention.self.query.weight as encoder.layer.3.attention.self.query.weight.
SAVING bert.encoder.layer.3.attention.self.query.bias as encoder.layer.3.attention.self.query.bias.
SAVING bert.encoder.layer.3.attention.self.key.weight as encoder.layer.3.attention.self.key.weight.
SAVING bert.encoder.layer.3.attention.self.key.bias as encoder.layer.3.attention.self.key.bias.
SAVING bert.encoder.layer.3.attention.self.value.weight as encoder.layer.3.attention.self.value.weight.
SAVING bert.encoder.layer.3.attention.self.value.bias as encoder.layer.3.attention.self.value.bias.
SAVING bert.encoder.layer.3.attention.output.dense.weight as encoder.layer.3.attention.output.dense.weight.
SAVING bert.encoder.layer.3.attention.output.dense.bias as encoder.layer.3.attention.output.dense.bias.
SAVING bert.encoder.layer.3.attention.output.LayerNorm.weight as encoder.layer.3.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.3.attention.output.LayerNorm.bias as encoder.layer.3.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.3.intermediate.dense.weight as encoder.layer.3.intermediate.dense.weight.
SAVING bert.encoder.layer.3.intermediate.dense.bias as encoder.layer.3.intermediate.dense.bias.
SAVING bert.encoder.layer.3.output.dense.weight as encoder.layer.3.output.dense.weight.
SAVING bert.encoder.layer.3.output.dense.bias as encoder.layer.3.output.dense.bias.
SAVING bert.encoder.layer.3.output.LayerNorm.weight as encoder.layer.3.output.LayerNorm.weight.
SAVING bert.encoder.layer.3.output.LayerNorm.bias as encoder.layer.3.output.LayerNorm.bias.
SAVING bert.encoder.layer.4.attention.self.query.weight as encoder.layer.4.attention.self.query.weight.
SAVING bert.encoder.layer.4.attention.self.query.bias as encoder.layer.4.attention.self.query.bias.
SAVING bert.encoder.layer.4.attention.self.key.weight as encoder.layer.4.attention.self.key.weight.
SAVING bert.encoder.layer.4.attention.self.key.bias as encoder.layer.4.attention.self.key.bias.
SAVING bert.encoder.layer.4.attention.self.value.weight as encoder.layer.4.attention.self.value.weight.
SAVING bert.encoder.layer.4.attention.self.value.bias as encoder.layer.4.attention.self.value.bias.
SAVING bert.encoder.layer.4.attention.output.dense.weight as encoder.layer.4.attention.output.dense.weight.
SAVING bert.encoder.layer.4.attention.output.dense.bias as encoder.layer.4.attention.output.dense.bias.
SAVING bert.encoder.layer.4.attention.output.LayerNorm.weight as encoder.layer.4.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.4.attention.output.LayerNorm.bias as encoder.layer.4.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.4.intermediate.dense.weight as encoder.layer.4.intermediate.dense.weight.
SAVING bert.encoder.layer.4.intermediate.dense.bias as encoder.layer.4.intermediate.dense.bias.
SAVING bert.encoder.layer.4.output.dense.weight as encoder.layer.4.output.dense.weight.
SAVING bert.encoder.layer.4.output.dense.bias as encoder.layer.4.output.dense.bias.
SAVING bert.encoder.layer.4.output.LayerNorm.weight as encoder.layer.4.output.LayerNorm.weight.
SAVING bert.encoder.layer.4.output.LayerNorm.bias as encoder.layer.4.output.LayerNorm.bias.
SAVING bert.encoder.layer.5.attention.self.query.weight as encoder.layer.5.attention.self.query.weight.
SAVING bert.encoder.layer.5.attention.self.query.bias as encoder.layer.5.attention.self.query.bias.
SAVING bert.encoder.layer.5.attention.self.key.weight as encoder.layer.5.attention.self.key.weight.
SAVING bert.encoder.layer.5.attention.self.key.bias as encoder.layer.5.attention.self.key.bias.
SAVING bert.encoder.layer.5.attention.self.value.weight as encoder.layer.5.attention.self.value.weight.
SAVING bert.encoder.layer.5.attention.self.value.bias as encoder.layer.5.attention.self.value.bias.
SAVING bert.encoder.layer.5.attention.output.dense.weight as encoder.layer.5.attention.output.dense.weight.
SAVING bert.encoder.layer.5.attention.output.dense.bias as encoder.layer.5.attention.output.dense.bias.
SAVING bert.encoder.layer.5.attention.output.LayerNorm.weight as encoder.layer.5.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.5.attention.output.LayerNorm.bias as encoder.layer.5.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.5.intermediate.dense.weight as encoder.layer.5.intermediate.dense.weight.
SAVING bert.encoder.layer.5.intermediate.dense.bias as encoder.layer.5.intermediate.dense.bias.
SAVING bert.encoder.layer.5.output.dense.weight as encoder.layer.5.output.dense.weight.
SAVING bert.encoder.layer.5.output.dense.bias as encoder.layer.5.output.dense.bias.
SAVING bert.encoder.layer.5.output.LayerNorm.weight as encoder.layer.5.output.LayerNorm.weight.
SAVING bert.encoder.layer.5.output.LayerNorm.bias as encoder.layer.5.output.LayerNorm.bias.
SAVING bert.encoder.layer.6.attention.self.query.weight as encoder.layer.6.attention.self.query.weight.
SAVING bert.encoder.layer.6.attention.self.query.bias as encoder.layer.6.attention.self.query.bias.
SAVING bert.encoder.layer.6.attention.self.key.weight as encoder.layer.6.attention.self.key.weight.
SAVING bert.encoder.layer.6.attention.self.key.bias as encoder.layer.6.attention.self.key.bias.
SAVING bert.encoder.layer.6.attention.self.value.weight as encoder.layer.6.attention.self.value.weight.
SAVING bert.encoder.layer.6.attention.self.value.bias as encoder.layer.6.attention.self.value.bias.
SAVING bert.encoder.layer.6.attention.output.dense.weight as encoder.layer.6.attention.output.dense.weight.
SAVING bert.encoder.layer.6.attention.output.dense.bias as encoder.layer.6.attention.output.dense.bias.
SAVING bert.encoder.layer.6.attention.output.LayerNorm.weight as encoder.layer.6.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.6.attention.output.LayerNorm.bias as encoder.layer.6.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.6.intermediate.dense.weight as encoder.layer.6.intermediate.dense.weight.
SAVING bert.encoder.layer.6.intermediate.dense.bias as encoder.layer.6.intermediate.dense.bias.
SAVING bert.encoder.layer.6.output.dense.weight as encoder.layer.6.output.dense.weight.
SAVING bert.encoder.layer.6.output.dense.bias as encoder.layer.6.output.dense.bias.
SAVING bert.encoder.layer.6.output.LayerNorm.weight as encoder.layer.6.output.LayerNorm.weight.
SAVING bert.encoder.layer.6.output.LayerNorm.bias as encoder.layer.6.output.LayerNorm.bias.
SAVING bert.encoder.layer.7.attention.self.query.weight as encoder.layer.7.attention.self.query.weight.
SAVING bert.encoder.layer.7.attention.self.query.bias as encoder.layer.7.attention.self.query.bias.
SAVING bert.encoder.layer.7.attention.self.key.weight as encoder.layer.7.attention.self.key.weight.
SAVING bert.encoder.layer.7.attention.self.key.bias as encoder.layer.7.attention.self.key.bias.
SAVING bert.encoder.layer.7.attention.self.value.weight as encoder.layer.7.attention.self.value.weight.
SAVING bert.encoder.layer.7.attention.self.value.bias as encoder.layer.7.attention.self.value.bias.
SAVING bert.encoder.layer.7.attention.output.dense.weight as encoder.layer.7.attention.output.dense.weight.
SAVING bert.encoder.layer.7.attention.output.dense.bias as encoder.layer.7.attention.output.dense.bias.
SAVING bert.encoder.layer.7.attention.output.LayerNorm.weight as encoder.layer.7.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.7.attention.output.LayerNorm.bias as encoder.layer.7.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.7.intermediate.dense.weight as encoder.layer.7.intermediate.dense.weight.
SAVING bert.encoder.layer.7.intermediate.dense.bias as encoder.layer.7.intermediate.dense.bias.
SAVING bert.encoder.layer.7.output.dense.weight as encoder.layer.7.output.dense.weight.
SAVING bert.encoder.layer.7.output.dense.bias as encoder.layer.7.output.dense.bias.
SAVING bert.encoder.layer.7.output.LayerNorm.weight as encoder.layer.7.output.LayerNorm.weight.
SAVING bert.encoder.layer.7.output.LayerNorm.bias as encoder.layer.7.output.LayerNorm.bias.
SAVING bert.encoder.layer.8.attention.self.query.weight as encoder.layer.8.attention.self.query.weight.
SAVING bert.encoder.layer.8.attention.self.query.bias as encoder.layer.8.attention.self.query.bias.
SAVING bert.encoder.layer.8.attention.self.key.weight as encoder.layer.8.attention.self.key.weight.
SAVING bert.encoder.layer.8.attention.self.key.bias as encoder.layer.8.attention.self.key.bias.
SAVING bert.encoder.layer.8.attention.self.value.weight as encoder.layer.8.attention.self.value.weight.
SAVING bert.encoder.layer.8.attention.self.value.bias as encoder.layer.8.attention.self.value.bias.
SAVING bert.encoder.layer.8.attention.output.dense.weight as encoder.layer.8.attention.output.dense.weight.
SAVING bert.encoder.layer.8.attention.output.dense.bias as encoder.layer.8.attention.output.dense.bias.
SAVING bert.encoder.layer.8.attention.output.LayerNorm.weight as encoder.layer.8.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.8.attention.output.LayerNorm.bias as encoder.layer.8.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.8.intermediate.dense.weight as encoder.layer.8.intermediate.dense.weight.
SAVING bert.encoder.layer.8.intermediate.dense.bias as encoder.layer.8.intermediate.dense.bias.
SAVING bert.encoder.layer.8.output.dense.weight as encoder.layer.8.output.dense.weight.
SAVING bert.encoder.layer.8.output.dense.bias as encoder.layer.8.output.dense.bias.
SAVING bert.encoder.layer.8.output.LayerNorm.weight as encoder.layer.8.output.LayerNorm.weight.
SAVING bert.encoder.layer.8.output.LayerNorm.bias as encoder.layer.8.output.LayerNorm.bias.
SAVING bert.encoder.layer.9.attention.self.query.weight as encoder.layer.9.attention.self.query.weight.
SAVING bert.encoder.layer.9.attention.self.query.bias as encoder.layer.9.attention.self.query.bias.
SAVING bert.encoder.layer.9.attention.self.key.weight as encoder.layer.9.attention.self.key.weight.
SAVING bert.encoder.layer.9.attention.self.key.bias as encoder.layer.9.attention.self.key.bias.
SAVING bert.encoder.layer.9.attention.self.value.weight as encoder.layer.9.attention.self.value.weight.
SAVING bert.encoder.layer.9.attention.self.value.bias as encoder.layer.9.attention.self.value.bias.
SAVING bert.encoder.layer.9.attention.output.dense.weight as encoder.layer.9.attention.output.dense.weight.
SAVING bert.encoder.layer.9.attention.output.dense.bias as encoder.layer.9.attention.output.dense.bias.
SAVING bert.encoder.layer.9.attention.output.LayerNorm.weight as encoder.layer.9.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.9.attention.output.LayerNorm.bias as encoder.layer.9.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.9.intermediate.dense.weight as encoder.layer.9.intermediate.dense.weight.
SAVING bert.encoder.layer.9.intermediate.dense.bias as encoder.layer.9.intermediate.dense.bias.
SAVING bert.encoder.layer.9.output.dense.weight as encoder.layer.9.output.dense.weight.
SAVING bert.encoder.layer.9.output.dense.bias as encoder.layer.9.output.dense.bias.
SAVING bert.encoder.layer.9.output.LayerNorm.weight as encoder.layer.9.output.LayerNorm.weight.
SAVING bert.encoder.layer.9.output.LayerNorm.bias as encoder.layer.9.output.LayerNorm.bias.
SAVING bert.encoder.layer.10.attention.self.query.weight as encoder.layer.10.attention.self.query.weight.
SAVING bert.encoder.layer.10.attention.self.query.bias as encoder.layer.10.attention.self.query.bias.
SAVING bert.encoder.layer.10.attention.self.key.weight as encoder.layer.10.attention.self.key.weight.
SAVING bert.encoder.layer.10.attention.self.key.bias as encoder.layer.10.attention.self.key.bias.
SAVING bert.encoder.layer.10.attention.self.value.weight as encoder.layer.10.attention.self.value.weight.
SAVING bert.encoder.layer.10.attention.self.value.bias as encoder.layer.10.attention.self.value.bias.
SAVING bert.encoder.layer.10.attention.output.dense.weight as encoder.layer.10.attention.output.dense.weight.
SAVING bert.encoder.layer.10.attention.output.dense.bias as encoder.layer.10.attention.output.dense.bias.
SAVING bert.encoder.layer.10.attention.output.LayerNorm.weight as encoder.layer.10.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.10.attention.output.LayerNorm.bias as encoder.layer.10.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.10.intermediate.dense.weight as encoder.layer.10.intermediate.dense.weight.
SAVING bert.encoder.layer.10.intermediate.dense.bias as encoder.layer.10.intermediate.dense.bias.
SAVING bert.encoder.layer.10.output.dense.weight as encoder.layer.10.output.dense.weight.
SAVING bert.encoder.layer.10.output.dense.bias as encoder.layer.10.output.dense.bias.
SAVING bert.encoder.layer.10.output.LayerNorm.weight as encoder.layer.10.output.LayerNorm.weight.
SAVING bert.encoder.layer.10.output.LayerNorm.bias as encoder.layer.10.output.LayerNorm.bias.
SAVING bert.encoder.layer.11.attention.self.query.weight as encoder.layer.11.attention.self.query.weight.
SAVING bert.encoder.layer.11.attention.self.query.bias as encoder.layer.11.attention.self.query.bias.
SAVING bert.encoder.layer.11.attention.self.key.weight as encoder.layer.11.attention.self.key.weight.
SAVING bert.encoder.layer.11.attention.self.key.bias as encoder.layer.11.attention.self.key.bias.
SAVING bert.encoder.layer.11.attention.self.value.weight as encoder.layer.11.attention.self.value.weight.
SAVING bert.encoder.layer.11.attention.self.value.bias as encoder.layer.11.attention.self.value.bias.
SAVING bert.encoder.layer.11.attention.output.dense.weight as encoder.layer.11.attention.output.dense.weight.
SAVING bert.encoder.layer.11.attention.output.dense.bias as encoder.layer.11.attention.output.dense.bias.
SAVING bert.encoder.layer.11.attention.output.LayerNorm.weight as encoder.layer.11.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.11.attention.output.LayerNorm.bias as encoder.layer.11.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.11.intermediate.dense.weight as encoder.layer.11.intermediate.dense.weight.
SAVING bert.encoder.layer.11.intermediate.dense.bias as encoder.layer.11.intermediate.dense.bias.
SAVING bert.encoder.layer.11.output.dense.weight as encoder.layer.11.output.dense.weight.
SAVING bert.encoder.layer.11.output.dense.bias as encoder.layer.11.output.dense.bias.
SAVING bert.encoder.layer.11.output.LayerNorm.weight as encoder.layer.11.output.LayerNorm.weight.
SAVING bert.encoder.layer.11.output.LayerNorm.bias as encoder.layer.11.output.LayerNorm.bias.
SAVING bert.encoder.layer.12.attention.self.query.weight as encoder.layer.12.attention.self.query.weight.
SAVING bert.encoder.layer.12.attention.self.query.bias as encoder.layer.12.attention.self.query.bias.
SAVING bert.encoder.layer.12.attention.self.key.weight as encoder.layer.12.attention.self.key.weight.
SAVING bert.encoder.layer.12.attention.self.key.bias as encoder.layer.12.attention.self.key.bias.
SAVING bert.encoder.layer.12.attention.self.value.weight as encoder.layer.12.attention.self.value.weight.
SAVING bert.encoder.layer.12.attention.self.value.bias as encoder.layer.12.attention.self.value.bias.
SAVING bert.encoder.layer.12.attention.output.dense.weight as encoder.layer.12.attention.output.dense.weight.
SAVING bert.encoder.layer.12.attention.output.dense.bias as encoder.layer.12.attention.output.dense.bias.
SAVING bert.encoder.layer.12.attention.output.LayerNorm.weight as encoder.layer.12.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.12.attention.output.LayerNorm.bias as encoder.layer.12.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.12.intermediate.dense.weight as encoder.layer.12.intermediate.dense.weight.
SAVING bert.encoder.layer.12.intermediate.dense.bias as encoder.layer.12.intermediate.dense.bias.
SAVING bert.encoder.layer.12.output.dense.weight as encoder.layer.12.output.dense.weight.
SAVING bert.encoder.layer.12.output.dense.bias as encoder.layer.12.output.dense.bias.
SAVING bert.encoder.layer.12.output.LayerNorm.weight as encoder.layer.12.output.LayerNorm.weight.
SAVING bert.encoder.layer.12.output.LayerNorm.bias as encoder.layer.12.output.LayerNorm.bias.
SAVING bert.encoder.layer.13.attention.self.query.weight as encoder.layer.13.attention.self.query.weight.
SAVING bert.encoder.layer.13.attention.self.query.bias as encoder.layer.13.attention.self.query.bias.
SAVING bert.encoder.layer.13.attention.self.key.weight as encoder.layer.13.attention.self.key.weight.
SAVING bert.encoder.layer.13.attention.self.key.bias as encoder.layer.13.attention.self.key.bias.
SAVING bert.encoder.layer.13.attention.self.value.weight as encoder.layer.13.attention.self.value.weight.
SAVING bert.encoder.layer.13.attention.self.value.bias as encoder.layer.13.attention.self.value.bias.
SAVING bert.encoder.layer.13.attention.output.dense.weight as encoder.layer.13.attention.output.dense.weight.
SAVING bert.encoder.layer.13.attention.output.dense.bias as encoder.layer.13.attention.output.dense.bias.
SAVING bert.encoder.layer.13.attention.output.LayerNorm.weight as encoder.layer.13.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.13.attention.output.LayerNorm.bias as encoder.layer.13.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.13.intermediate.dense.weight as encoder.layer.13.intermediate.dense.weight.
SAVING bert.encoder.layer.13.intermediate.dense.bias as encoder.layer.13.intermediate.dense.bias.
SAVING bert.encoder.layer.13.output.dense.weight as encoder.layer.13.output.dense.weight.
SAVING bert.encoder.layer.13.output.dense.bias as encoder.layer.13.output.dense.bias.
SAVING bert.encoder.layer.13.output.LayerNorm.weight as encoder.layer.13.output.LayerNorm.weight.
SAVING bert.encoder.layer.13.output.LayerNorm.bias as encoder.layer.13.output.LayerNorm.bias.
SAVING bert.encoder.layer.14.attention.self.query.weight as encoder.layer.14.attention.self.query.weight.
SAVING bert.encoder.layer.14.attention.self.query.bias as encoder.layer.14.attention.self.query.bias.
SAVING bert.encoder.layer.14.attention.self.key.weight as encoder.layer.14.attention.self.key.weight.
SAVING bert.encoder.layer.14.attention.self.key.bias as encoder.layer.14.attention.self.key.bias.
SAVING bert.encoder.layer.14.attention.self.value.weight as encoder.layer.14.attention.self.value.weight.
SAVING bert.encoder.layer.14.attention.self.value.bias as encoder.layer.14.attention.self.value.bias.
SAVING bert.encoder.layer.14.attention.output.dense.weight as encoder.layer.14.attention.output.dense.weight.
SAVING bert.encoder.layer.14.attention.output.dense.bias as encoder.layer.14.attention.output.dense.bias.
SAVING bert.encoder.layer.14.attention.output.LayerNorm.weight as encoder.layer.14.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.14.attention.output.LayerNorm.bias as encoder.layer.14.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.14.intermediate.dense.weight as encoder.layer.14.intermediate.dense.weight.
SAVING bert.encoder.layer.14.intermediate.dense.bias as encoder.layer.14.intermediate.dense.bias.
SAVING bert.encoder.layer.14.output.dense.weight as encoder.layer.14.output.dense.weight.
SAVING bert.encoder.layer.14.output.dense.bias as encoder.layer.14.output.dense.bias.
SAVING bert.encoder.layer.14.output.LayerNorm.weight as encoder.layer.14.output.LayerNorm.weight.
SAVING bert.encoder.layer.14.output.LayerNorm.bias as encoder.layer.14.output.LayerNorm.bias.
SAVING bert.encoder.layer.15.attention.self.query.weight as encoder.layer.15.attention.self.query.weight.
SAVING bert.encoder.layer.15.attention.self.query.bias as encoder.layer.15.attention.self.query.bias.
SAVING bert.encoder.layer.15.attention.self.key.weight as encoder.layer.15.attention.self.key.weight.
SAVING bert.encoder.layer.15.attention.self.key.bias as encoder.layer.15.attention.self.key.bias.
SAVING bert.encoder.layer.15.attention.self.value.weight as encoder.layer.15.attention.self.value.weight.
SAVING bert.encoder.layer.15.attention.self.value.bias as encoder.layer.15.attention.self.value.bias.
SAVING bert.encoder.layer.15.attention.output.dense.weight as encoder.layer.15.attention.output.dense.weight.
SAVING bert.encoder.layer.15.attention.output.dense.bias as encoder.layer.15.attention.output.dense.bias.
SAVING bert.encoder.layer.15.attention.output.LayerNorm.weight as encoder.layer.15.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.15.attention.output.LayerNorm.bias as encoder.layer.15.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.15.intermediate.dense.weight as encoder.layer.15.intermediate.dense.weight.
SAVING bert.encoder.layer.15.intermediate.dense.bias as encoder.layer.15.intermediate.dense.bias.
SAVING bert.encoder.layer.15.output.dense.weight as encoder.layer.15.output.dense.weight.
SAVING bert.encoder.layer.15.output.dense.bias as encoder.layer.15.output.dense.bias.
SAVING bert.encoder.layer.15.output.LayerNorm.weight as encoder.layer.15.output.LayerNorm.weight.
SAVING bert.encoder.layer.15.output.LayerNorm.bias as encoder.layer.15.output.LayerNorm.bias.
SAVING bert.encoder.layer.16.attention.self.query.weight as encoder.layer.16.attention.self.query.weight.
SAVING bert.encoder.layer.16.attention.self.query.bias as encoder.layer.16.attention.self.query.bias.
SAVING bert.encoder.layer.16.attention.self.key.weight as encoder.layer.16.attention.self.key.weight.
SAVING bert.encoder.layer.16.attention.self.key.bias as encoder.layer.16.attention.self.key.bias.
SAVING bert.encoder.layer.16.attention.self.value.weight as encoder.layer.16.attention.self.value.weight.
SAVING bert.encoder.layer.16.attention.self.value.bias as encoder.layer.16.attention.self.value.bias.
SAVING bert.encoder.layer.16.attention.output.dense.weight as encoder.layer.16.attention.output.dense.weight.
SAVING bert.encoder.layer.16.attention.output.dense.bias as encoder.layer.16.attention.output.dense.bias.
SAVING bert.encoder.layer.16.attention.output.LayerNorm.weight as encoder.layer.16.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.16.attention.output.LayerNorm.bias as encoder.layer.16.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.16.intermediate.dense.weight as encoder.layer.16.intermediate.dense.weight.
SAVING bert.encoder.layer.16.intermediate.dense.bias as encoder.layer.16.intermediate.dense.bias.
SAVING bert.encoder.layer.16.output.dense.weight as encoder.layer.16.output.dense.weight.
SAVING bert.encoder.layer.16.output.dense.bias as encoder.layer.16.output.dense.bias.
SAVING bert.encoder.layer.16.output.LayerNorm.weight as encoder.layer.16.output.LayerNorm.weight.
SAVING bert.encoder.layer.16.output.LayerNorm.bias as encoder.layer.16.output.LayerNorm.bias.
SAVING bert.encoder.layer.17.attention.self.query.weight as encoder.layer.17.attention.self.query.weight.
SAVING bert.encoder.layer.17.attention.self.query.bias as encoder.layer.17.attention.self.query.bias.
SAVING bert.encoder.layer.17.attention.self.key.weight as encoder.layer.17.attention.self.key.weight.
SAVING bert.encoder.layer.17.attention.self.key.bias as encoder.layer.17.attention.self.key.bias.
SAVING bert.encoder.layer.17.attention.self.value.weight as encoder.layer.17.attention.self.value.weight.
SAVING bert.encoder.layer.17.attention.self.value.bias as encoder.layer.17.attention.self.value.bias.
SAVING bert.encoder.layer.17.attention.output.dense.weight as encoder.layer.17.attention.output.dense.weight.
SAVING bert.encoder.layer.17.attention.output.dense.bias as encoder.layer.17.attention.output.dense.bias.
SAVING bert.encoder.layer.17.attention.output.LayerNorm.weight as encoder.layer.17.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.17.attention.output.LayerNorm.bias as encoder.layer.17.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.17.intermediate.dense.weight as encoder.layer.17.intermediate.dense.weight.
SAVING bert.encoder.layer.17.intermediate.dense.bias as encoder.layer.17.intermediate.dense.bias.
SAVING bert.encoder.layer.17.output.dense.weight as encoder.layer.17.output.dense.weight.
SAVING bert.encoder.layer.17.output.dense.bias as encoder.layer.17.output.dense.bias.
SAVING bert.encoder.layer.17.output.LayerNorm.weight as encoder.layer.17.output.LayerNorm.weight.
SAVING bert.encoder.layer.17.output.LayerNorm.bias as encoder.layer.17.output.LayerNorm.bias.
SAVING bert.encoder.layer.18.attention.self.query.weight as encoder.layer.18.attention.self.query.weight.
SAVING bert.encoder.layer.18.attention.self.query.bias as encoder.layer.18.attention.self.query.bias.
SAVING bert.encoder.layer.18.attention.self.key.weight as encoder.layer.18.attention.self.key.weight.
SAVING bert.encoder.layer.18.attention.self.key.bias as encoder.layer.18.attention.self.key.bias.
SAVING bert.encoder.layer.18.attention.self.value.weight as encoder.layer.18.attention.self.value.weight.
SAVING bert.encoder.layer.18.attention.self.value.bias as encoder.layer.18.attention.self.value.bias.
SAVING bert.encoder.layer.18.attention.output.dense.weight as encoder.layer.18.attention.output.dense.weight.
SAVING bert.encoder.layer.18.attention.output.dense.bias as encoder.layer.18.attention.output.dense.bias.
SAVING bert.encoder.layer.18.attention.output.LayerNorm.weight as encoder.layer.18.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.18.attention.output.LayerNorm.bias as encoder.layer.18.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.18.intermediate.dense.weight as encoder.layer.18.intermediate.dense.weight.
SAVING bert.encoder.layer.18.intermediate.dense.bias as encoder.layer.18.intermediate.dense.bias.
SAVING bert.encoder.layer.18.output.dense.weight as encoder.layer.18.output.dense.weight.
SAVING bert.encoder.layer.18.output.dense.bias as encoder.layer.18.output.dense.bias.
SAVING bert.encoder.layer.18.output.LayerNorm.weight as encoder.layer.18.output.LayerNorm.weight.
SAVING bert.encoder.layer.18.output.LayerNorm.bias as encoder.layer.18.output.LayerNorm.bias.
SAVING bert.encoder.layer.19.attention.self.query.weight as encoder.layer.19.attention.self.query.weight.
SAVING bert.encoder.layer.19.attention.self.query.bias as encoder.layer.19.attention.self.query.bias.
SAVING bert.encoder.layer.19.attention.self.key.weight as encoder.layer.19.attention.self.key.weight.
SAVING bert.encoder.layer.19.attention.self.key.bias as encoder.layer.19.attention.self.key.bias.
SAVING bert.encoder.layer.19.attention.self.value.weight as encoder.layer.19.attention.self.value.weight.
SAVING bert.encoder.layer.19.attention.self.value.bias as encoder.layer.19.attention.self.value.bias.
SAVING bert.encoder.layer.19.attention.output.dense.weight as encoder.layer.19.attention.output.dense.weight.
SAVING bert.encoder.layer.19.attention.output.dense.bias as encoder.layer.19.attention.output.dense.bias.
SAVING bert.encoder.layer.19.attention.output.LayerNorm.weight as encoder.layer.19.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.19.attention.output.LayerNorm.bias as encoder.layer.19.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.19.intermediate.dense.weight as encoder.layer.19.intermediate.dense.weight.
SAVING bert.encoder.layer.19.intermediate.dense.bias as encoder.layer.19.intermediate.dense.bias.
SAVING bert.encoder.layer.19.output.dense.weight as encoder.layer.19.output.dense.weight.
SAVING bert.encoder.layer.19.output.dense.bias as encoder.layer.19.output.dense.bias.
SAVING bert.encoder.layer.19.output.LayerNorm.weight as encoder.layer.19.output.LayerNorm.weight.
SAVING bert.encoder.layer.19.output.LayerNorm.bias as encoder.layer.19.output.LayerNorm.bias.
SAVING bert.encoder.layer.20.attention.self.query.weight as encoder.layer.20.attention.self.query.weight.
SAVING bert.encoder.layer.20.attention.self.query.bias as encoder.layer.20.attention.self.query.bias.
SAVING bert.encoder.layer.20.attention.self.key.weight as encoder.layer.20.attention.self.key.weight.
SAVING bert.encoder.layer.20.attention.self.key.bias as encoder.layer.20.attention.self.key.bias.
SAVING bert.encoder.layer.20.attention.self.value.weight as encoder.layer.20.attention.self.value.weight.
SAVING bert.encoder.layer.20.attention.self.value.bias as encoder.layer.20.attention.self.value.bias.
SAVING bert.encoder.layer.20.attention.output.dense.weight as encoder.layer.20.attention.output.dense.weight.
SAVING bert.encoder.layer.20.attention.output.dense.bias as encoder.layer.20.attention.output.dense.bias.
SAVING bert.encoder.layer.20.attention.output.LayerNorm.weight as encoder.layer.20.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.20.attention.output.LayerNorm.bias as encoder.layer.20.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.20.intermediate.dense.weight as encoder.layer.20.intermediate.dense.weight.
SAVING bert.encoder.layer.20.intermediate.dense.bias as encoder.layer.20.intermediate.dense.bias.
SAVING bert.encoder.layer.20.output.dense.weight as encoder.layer.20.output.dense.weight.
SAVING bert.encoder.layer.20.output.dense.bias as encoder.layer.20.output.dense.bias.
SAVING bert.encoder.layer.20.output.LayerNorm.weight as encoder.layer.20.output.LayerNorm.weight.
SAVING bert.encoder.layer.20.output.LayerNorm.bias as encoder.layer.20.output.LayerNorm.bias.
SAVING bert.encoder.layer.21.attention.self.query.weight as encoder.layer.21.attention.self.query.weight.
SAVING bert.encoder.layer.21.attention.self.query.bias as encoder.layer.21.attention.self.query.bias.
SAVING bert.encoder.layer.21.attention.self.key.weight as encoder.layer.21.attention.self.key.weight.
SAVING bert.encoder.layer.21.attention.self.key.bias as encoder.layer.21.attention.self.key.bias.
SAVING bert.encoder.layer.21.attention.self.value.weight as encoder.layer.21.attention.self.value.weight.
SAVING bert.encoder.layer.21.attention.self.value.bias as encoder.layer.21.attention.self.value.bias.
SAVING bert.encoder.layer.21.attention.output.dense.weight as encoder.layer.21.attention.output.dense.weight.
SAVING bert.encoder.layer.21.attention.output.dense.bias as encoder.layer.21.attention.output.dense.bias.
SAVING bert.encoder.layer.21.attention.output.LayerNorm.weight as encoder.layer.21.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.21.attention.output.LayerNorm.bias as encoder.layer.21.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.21.intermediate.dense.weight as encoder.layer.21.intermediate.dense.weight.
SAVING bert.encoder.layer.21.intermediate.dense.bias as encoder.layer.21.intermediate.dense.bias.
SAVING bert.encoder.layer.21.output.dense.weight as encoder.layer.21.output.dense.weight.
SAVING bert.encoder.layer.21.output.dense.bias as encoder.layer.21.output.dense.bias.
SAVING bert.encoder.layer.21.output.LayerNorm.weight as encoder.layer.21.output.LayerNorm.weight.
SAVING bert.encoder.layer.21.output.LayerNorm.bias as encoder.layer.21.output.LayerNorm.bias.
SAVING bert.encoder.layer.22.attention.self.query.weight as encoder.layer.22.attention.self.query.weight.
SAVING bert.encoder.layer.22.attention.self.query.bias as encoder.layer.22.attention.self.query.bias.
SAVING bert.encoder.layer.22.attention.self.key.weight as encoder.layer.22.attention.self.key.weight.
SAVING bert.encoder.layer.22.attention.self.key.bias as encoder.layer.22.attention.self.key.bias.
SAVING bert.encoder.layer.22.attention.self.value.weight as encoder.layer.22.attention.self.value.weight.
SAVING bert.encoder.layer.22.attention.self.value.bias as encoder.layer.22.attention.self.value.bias.
SAVING bert.encoder.layer.22.attention.output.dense.weight as encoder.layer.22.attention.output.dense.weight.
SAVING bert.encoder.layer.22.attention.output.dense.bias as encoder.layer.22.attention.output.dense.bias.
SAVING bert.encoder.layer.22.attention.output.LayerNorm.weight as encoder.layer.22.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.22.attention.output.LayerNorm.bias as encoder.layer.22.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.22.intermediate.dense.weight as encoder.layer.22.intermediate.dense.weight.
SAVING bert.encoder.layer.22.intermediate.dense.bias as encoder.layer.22.intermediate.dense.bias.
SAVING bert.encoder.layer.22.output.dense.weight as encoder.layer.22.output.dense.weight.
SAVING bert.encoder.layer.22.output.dense.bias as encoder.layer.22.output.dense.bias.
SAVING bert.encoder.layer.22.output.LayerNorm.weight as encoder.layer.22.output.LayerNorm.weight.
SAVING bert.encoder.layer.22.output.LayerNorm.bias as encoder.layer.22.output.LayerNorm.bias.
SAVING bert.encoder.layer.23.attention.self.query.weight as encoder.layer.23.attention.self.query.weight.
SAVING bert.encoder.layer.23.attention.self.query.bias as encoder.layer.23.attention.self.query.bias.
SAVING bert.encoder.layer.23.attention.self.key.weight as encoder.layer.23.attention.self.key.weight.
SAVING bert.encoder.layer.23.attention.self.key.bias as encoder.layer.23.attention.self.key.bias.
SAVING bert.encoder.layer.23.attention.self.value.weight as encoder.layer.23.attention.self.value.weight.
SAVING bert.encoder.layer.23.attention.self.value.bias as encoder.layer.23.attention.self.value.bias.
SAVING bert.encoder.layer.23.attention.output.dense.weight as encoder.layer.23.attention.output.dense.weight.
SAVING bert.encoder.layer.23.attention.output.dense.bias as encoder.layer.23.attention.output.dense.bias.
SAVING bert.encoder.layer.23.attention.output.LayerNorm.weight as encoder.layer.23.attention.output.LayerNorm.weight.
SAVING bert.encoder.layer.23.attention.output.LayerNorm.bias as encoder.layer.23.attention.output.LayerNorm.bias.
SAVING bert.encoder.layer.23.intermediate.dense.weight as encoder.layer.23.intermediate.dense.weight.
SAVING bert.encoder.layer.23.intermediate.dense.bias as encoder.layer.23.intermediate.dense.bias.
SAVING bert.encoder.layer.23.output.dense.weight as encoder.layer.23.output.dense.weight.
SAVING bert.encoder.layer.23.output.dense.bias as encoder.layer.23.output.dense.bias.
SAVING bert.encoder.layer.23.output.LayerNorm.weight as encoder.layer.23.output.LayerNorm.weight.
SAVING bert.encoder.layer.23.output.LayerNorm.bias as encoder.layer.23.output.LayerNorm.bias.
SAVING bert.pooler.dense.weight as pooler.dense.weight.
SAVING bert.pooler.dense.bias as pooler.dense.bias.

Weights in loaded but not in model:
cls.predictions.bias
cls.predictions.decoder.weight
cls.predictions.transform.LayerNorm.bias
cls.predictions.transform.LayerNorm.weight
cls.predictions.transform.dense.bias
cls.predictions.transform.dense.weight
cls.seq_relationship.bias
cls.seq_relationship.weight
ctm_output.bias
ctm_output.weight

Weights in model but not in loaded:

Total Iters: 5375
Splits in Train data: ['train']
Splits in Valid data: ['dev_seen']
Batches: 1075
/home/ML_courses/DL2020/efratblaier/vilio_env/lib/python3.7/site-packages/torchcontrib/optim/swa.py:130: UserWarning: Casting swa_start, swa_freq to int
  warnings.warn("Casting swa_start, swa_freq to int")
tensor([-0.6000, -0.7959], device='cuda:0')
Load 1000 data from split(s) test_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 1000 images in file data/HM_img.tsv in 40 seconds.
Use 1000 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      1000 non-null   int64  
 1   proba   1000 non-null   float64
 2   label   1000 non-null   int64  
dtypes: float64(1), int64(2)
memory usage: 23.6 KB
None

Epoch(U) 0(250): Train AC 97.70 RA 99.7781 LOSS 158.0930

Epoch(U) 0(250): DEV AC 65.40 RA 76.5806 
Epoch(U) 0(250): BEST AC 65.40 RA 76.5806 
Load 1000 data from split(s) test_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 1000 images in file data/HM_img.tsv in 40 seconds.
Use 1000 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      1000 non-null   int64  
 1   proba   1000 non-null   float64
 2   label   1000 non-null   int64  
dtypes: float64(1), int64(2)
memory usage: 23.6 KB
None

Epoch(U) 0(500): Train AC 98.80 RA 99.9263 LOSS 12.0400

Epoch(U) 0(500): DEV AC 67.20 RA 76.6110 
Epoch(U) 0(500): BEST AC 67.20 RA 76.6110 

Epoch(U) 0(750): Train AC 98.82 RA 99.7674 LOSS 157.3021

Epoch(U) 0(750): DEV AC 69.60 RA 75.8237 
Epoch(U) 0(750): BEST AC 67.20 RA 76.6110 

Epoch(U) 0(1000): Train AC 98.74 RA 99.7035 LOSS 182.2970

Epoch(U) 0(1000): DEV AC 69.80 RA 76.3350 
Epoch(U) 0(1000): BEST AC 67.20 RA 76.6110 
tensor([-1.2278e-05, -1.1312e+01], device='cuda:0')

Epoch(U) 1(1250): Train AC 98.79 RA 99.7292 LOSS 157.6708

Epoch(U) 1(1250): DEV AC 67.60 RA 75.4725 
Epoch(U) 1(1250): BEST AC 67.20 RA 76.6110 
Load 1000 data from split(s) test_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 1000 images in file data/HM_img.tsv in 40 seconds.
Use 1000 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      1000 non-null   int64  
 1   proba   1000 non-null   float64
 2   label   1000 non-null   int64  
dtypes: float64(1), int64(2)
memory usage: 23.6 KB
None

Epoch(U) 1(1500): Train AC 98.74 RA 99.7148 LOSS 168.0872

Epoch(U) 1(1500): DEV AC 68.40 RA 77.1903 
Epoch(U) 1(1500): BEST AC 68.40 RA 77.1903 

Epoch(U) 1(1750): Train AC 98.67 RA 99.7102 LOSS 188.5455

Epoch(U) 1(1750): DEV AC 67.60 RA 75.4973 
Epoch(U) 1(1750): BEST AC 68.40 RA 77.1903 

Epoch(U) 1(2000): Train AC 98.73 RA 99.7382 LOSS 135.8065

Epoch(U) 1(2000): DEV AC 65.60 RA 75.8109 
Epoch(U) 1(2000): BEST AC 68.40 RA 77.1903 
tensor([-1.4006e-04, -8.8735e+00], device='cuda:0')

Epoch(U) 2(2250): Train AC 99.38 RA 99.9609 LOSS 115.4625

Epoch(U) 2(2250): DEV AC 66.80 RA 76.3438 
Epoch(U) 2(2250): BEST AC 68.40 RA 77.1903 
Load 1000 data from split(s) test_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 1000 images in file data/HM_img.tsv in 41 seconds.
Use 1000 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      1000 non-null   int64  
 1   proba   1000 non-null   float64
 2   label   1000 non-null   int64  
dtypes: float64(1), int64(2)
memory usage: 23.6 KB
None

Epoch(U) 2(2500): Train AC 99.14 RA 99.8779 LOSS 112.5845

Epoch(U) 2(2500): DEV AC 68.40 RA 77.3975 
Epoch(U) 2(2500): BEST AC 68.40 RA 77.3975 
Load 1000 data from split(s) test_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 1000 images in file data/HM_img.tsv in 41 seconds.
Use 1000 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      1000 non-null   int64  
 1   proba   1000 non-null   float64
 2   label   1000 non-null   int64  
dtypes: float64(1), int64(2)
memory usage: 23.6 KB
None

Epoch(U) 2(2750): Train AC 99.04 RA 99.9058 LOSS 119.4408

Epoch(U) 2(2750): DEV AC 68.80 RA 77.5120 
Epoch(U) 2(2750): BEST AC 68.80 RA 77.5120 

Epoch(U) 2(3000): Train AC 99.10 RA 99.9132 LOSS 80.8868

Epoch(U) 2(3000): DEV AC 67.00 RA 76.8383 
Epoch(U) 2(3000): BEST AC 68.80 RA 77.5120 
tensor([-1.2572e+01, -3.4571e-06], device='cuda:0')

Epoch(U) 3(3250): Train AC 100.00 RA 100.0000 LOSS 83.8472

Epoch(U) 3(3250): DEV AC 69.20 RA 77.3743 
Epoch(U) 3(3250): BEST AC 68.80 RA 77.5120 

Epoch(U) 3(3500): Train AC 99.68 RA 99.9862 LOSS 40.8519

Epoch(U) 3(3500): DEV AC 68.20 RA 77.0999 
Epoch(U) 3(3500): BEST AC 68.80 RA 77.5120 

Epoch(U) 3(3750): Train AC 99.62 RA 99.9667 LOSS 47.7447

Epoch(U) 3(3750): DEV AC 68.00 RA 76.8351 
Epoch(U) 3(3750): BEST AC 68.80 RA 77.5120 

Epoch(U) 3(4000): Train AC 99.65 RA 99.9722 LOSS 37.5320

Epoch(U) 3(4000): DEV AC 68.80 RA 77.3127 
Epoch(U) 3(4000): BEST AC 68.80 RA 77.5120 

Epoch(U) 3(4250): Train AC 99.71 RA 99.9801 LOSS 12.8060

Epoch(U) 3(4250): DEV AC 68.80 RA 77.1335 
Epoch(U) 3(4250): BEST AC 68.80 RA 77.5120 
tensor([-1.1026e+01, -1.6212e-05], device='cuda:0')

Epoch(U) 4(4500): Train AC 99.25 RA 99.8977 LOSS 85.2719

Epoch(U) 4(4500): DEV AC 68.60 RA 75.3268 
Epoch(U) 4(4500): BEST AC 68.80 RA 77.5120 

Epoch(U) 4(4750): Train AC 99.00 RA 99.7620 LOSS 172.6907

Epoch(U) 4(4750): DEV AC 67.80 RA 74.8828 
Epoch(U) 4(4750): BEST AC 68.80 RA 77.5120 

Epoch(U) 4(5000): Train AC 98.62 RA 99.6255 LOSS 268.9864

Epoch(U) 4(5000): DEV AC 64.80 RA 73.5386 
Epoch(U) 4(5000): BEST AC 68.80 RA 77.5120 

Epoch(U) 4(5250): Train AC 98.53 RA 99.5335 LOSS 244.5646

Epoch(U) 4(5250): DEV AC 68.20 RA 76.3526 
Epoch(U) 4(5250): BEST AC 68.80 RA 77.5120 
Load 500 data from split(s) dev_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 500 images in file data/HM_img.tsv in 40 seconds.
Use 500 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 500 entries, 0 to 499
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      500 non-null    int64  
 1   proba   500 non-null    float64
 2   label   500 non-null    int64  
dtypes: float64(1), int64(2)
memory usage: 11.8 KB
None
(0.698, 0.7728552911619273)
Load 1000 data from split(s) test_seen.
Start to load Faster-RCNN detected objects from data/HM_img.tsv
Loaded 1000 images in file data/HM_img.tsv in 40 seconds.
Use 1000 data in torch dataset

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   id      1000 non-null   int64  
 1   proba   1000 non-null   float64
 2   label   1000 non-null   int64  
dtypes: float64(1), int64(2)
memory usage: 23.6 KB
None
